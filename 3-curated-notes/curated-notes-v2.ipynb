{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Initialize the notebook, loading the configuration and importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries required for the notebook\n",
    "import asyncio\n",
    "\n",
    "# Instatiate the config class\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from config.notebook_config import *\n",
    "config = notebook_config()\n",
    "# Load config from file\n",
    "config.load_config_from_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Load the data from a Word file, and store it in a data dictionary.\n",
    "\n",
    "Replace filename by the fullpath to the Word file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Load the document\n",
    "document = Document(\"mydoc.docx\")\n",
    "\n",
    "# Initialize an empty list for sessions and variables for the current session\n",
    "sessions = []\n",
    "current_session = None\n",
    "current_section = None\n",
    "\n",
    "# Define the section headers we're looking for\n",
    "sections = {\n",
    "    \"Author information:\": \"authorInfo\",\n",
    "    \"Affiliations:\": \"affiliations\",\n",
    "    \"Abstract:\": \"abstract\",\n",
    "    \"Session notes:\": \"sessionNotes\",\n",
    "    \"Transcript:\": \"transcript\"\n",
    "}\n",
    "\n",
    "# Iterate through paragraphs in the document\n",
    "for paragraph in document.paragraphs:\n",
    "    # Check if paragraph is a new session heading\n",
    "    if paragraph.style.style_id == \"Heading2\":\n",
    "        # If there is a current session, append it to the sessions list\n",
    "        if current_session is not None:\n",
    "            sessions.append(current_session)\n",
    "        \n",
    "        # Start a new session dictionary\n",
    "        current_session = {\n",
    "            \"title\": paragraph.text,\n",
    "            \"authorInfo\": \"\",\n",
    "            \"affiliations\": \"\",\n",
    "            \"abstract\": \"\",\n",
    "            \"sessionNotes\": \"\",\n",
    "            \"transcript\": \"\"\n",
    "        }\n",
    "        current_section = None\n",
    "    \n",
    "    # Check if the paragraph text starts with any of the defined section headers\n",
    "    elif any(paragraph.text.startswith(header) for header in sections.keys()):\n",
    "        # Set the current section based on the detected header\n",
    "        for header, key in sections.items():\n",
    "            if paragraph.text.startswith(header):\n",
    "                current_section = key\n",
    "                # Remove the header text to only store the content\n",
    "                current_session[current_section] = paragraph.text.replace(header, \"\").strip()\n",
    "                break\n",
    "    \n",
    "    # Append content to the current section\n",
    "    elif current_section is not None and current_session is not None:\n",
    "        # Append text with a new line for readability\n",
    "        current_session[current_section] += paragraph.text + \"\\n\"\n",
    "\n",
    "# Append the last session if it exists\n",
    "if current_session is not None:\n",
    "    sessions.append(current_session)\n",
    "\n",
    "# Display session titles and their structured content for verification\n",
    "print(f\"Found {len(sessions)} sessions\")\n",
    "for i, session in enumerate(sessions):\n",
    "    print(f\"{i}: {session['title']}\")\n",
    "    print(f\"Author Info: {session['authorInfo']}\")\n",
    "    print(f\"Affiliations: {session['affiliations']}\")\n",
    "    print(f\"Abstract: {session['abstract']}\")\n",
    "    print(f\"Session Notes: {session['sessionNotes']}\")\n",
    "    print(f\"Transcript: {session['transcript']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Initiate the Semantic Kernel and fire-up with OpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Semantic Kernel\n",
    "import semantic_kernel\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = semantic_kernel.Kernel()\n",
    "print(\"Kernel loaded.\")\n",
    "\n",
    "deployment = config.model\n",
    "endpoint = config.endpoint\n",
    "api_key = config.azure_api_key\n",
    "kernel.add_chat_service(\"dv\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "print(f\"Fire-up the kernel with {deployment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Load plug-ins required to curate the congress notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins_directory = \"../plugins\"\n",
    "\n",
    "# Import the semantic functions\n",
    "my_functions = kernel.import_semantic_skill_from_directory(plugins_directory, \"CreateReport\")\n",
    "\n",
    "print(\"Plugins loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Execute the \"curation\" process:\n",
    "* First it will replace abbreviations and acronyms by their full meaning\n",
    "* Then it will summarize the notes\n",
    "* It will then extract the key concepts, in a report format\n",
    "* Finally it will translate to Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "def load_credentials(filename):\n",
    "    with open(filename) as cred_file:\n",
    "        return json.load(cred_file)\n",
    "\n",
    "openai_keys_file = \"../credentials_openai.json\"\n",
    "openai_model_info = load_credentials(openai_keys_file)\n",
    "\n",
    "session_id = 0\n",
    "# Concatenate the necessary session details to provide full context for summarization\n",
    "input_str = (\n",
    "    f\"Author information: {sessions[session_id]['authorInfo']}\\n\"\n",
    "    f\"Affiliations: {sessions[session_id]['affiliations']}\\n\"\n",
    "    f\"Abstract: {sessions[session_id]['abstract']}\\n\"\n",
    "    f\"Transcript: {sessions[session_id]['transcript']}\\n\"\n",
    ")\n",
    "\n",
    "openai.api_type = openai_model_info[\"api_type\"]\n",
    "openai.api_key = openai_model_info[\"api_key\"]\n",
    "openai.api_base = openai_model_info[\"endpoint\"]\n",
    "openai.api_version = openai_model_info[\"model_version\"]\n",
    "\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=openai_model_info[\"deployment_id\"],\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI expert in Rett Syndrome, specialized on generating summaries of scientific sessions.\"},\n",
    "            {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"\n",
    "            \n",
    "            Summarize the following transcript of a session presented at the Rett Syndrome World Congress.\n",
    "            The goal is to provide a comprehensive yet concise overview of the session.\n",
    "            Please ensure the summary is suitable for individuals with a general knowledge of Rett Syndrome,\n",
    "            focusing on aspects that would be meaningful for families.\n",
    "\n",
    "            {input_str}\n",
    "            \"\"\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    summary = response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "except openai.error.RateLimitError as e:\n",
    "    retry_after = int(e.headers.get(\"Retry-After\", 8))\n",
    "    print(f\"Rate limited. Retrying in {retry_after} seconds.\")\n",
    "    time.sleep(retry_after)\n",
    "except openai.error.OpenAIError as e:\n",
    "    print(f\"Error generating analysis: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "print(summary)\n",
    "\n",
    "\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=openai_model_info[\"deployment_id\"],\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI expert in Rett Syndrome, specialized on generating summaries of scientific sessions.\"},\n",
    "            {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": f\"\"\"\n",
    "            \n",
    "            Based on the following summary of a session from the Rett Syndrome World Congress, create a list of key takeaways for families. The takeaways should be easy to understand and focus on practical insights or important points that may impact daily life, caregiving, or understanding of Rett Syndrome. Use bullet points to make the takeaways clear and actionable.\n",
    "\n",
    "            {summary}\n",
    "            \"\"\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    key_take_aways = response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "except openai.error.RateLimitError as e:\n",
    "    retry_after = int(e.headers.get(\"Retry-After\", 8))\n",
    "    print(f\"Rate limited. Retrying in {retry_after} seconds.\")\n",
    "    time.sleep(retry_after)\n",
    "except openai.error.OpenAIError as e:\n",
    "    print(f\"Error generating analysis: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "\n",
    "\n",
    "print(key_take_aways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import ContextVariables\n",
    "\n",
    "session_id = 0\n",
    "# Concatenate the necessary session details to provide full context for summarization\n",
    "input_str = (\n",
    "    f\"Author information: {sessions[session_id]['authorInfo']}\\n\"\n",
    "    f\"Affiliations: {sessions[session_id]['affiliations']}\\n\"\n",
    "    f\"Abstract: {sessions[session_id]['abstract']}\\n\"\n",
    "    f\"Transcript: {sessions[session_id]['transcript']}\\n\"\n",
    ")\n",
    "\n",
    "# Run the summarization task with the enriched input\n",
    "step1 = asyncio.create_task(kernel.run_async(my_functions[\"Summarize\"], input_str=input_str))\n",
    "step1_result = await step1\n",
    "\n",
    "print(step1_result.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import ContextVariables\n",
    "\n",
    "session_id = 0\n",
    "input_str = sessions[session_id][\"transcript\"]\n",
    "print(f\"Input string: {input_str}\")\n",
    "\n",
    "# Review notes from the previous step, and summarize the notes\n",
    "step1 = asyncio.create_task(kernel.run_async(my_functions[\"NoteReview\"], input_str=input_str))\n",
    "step1_result = await step1\n",
    "\n",
    "print(step1_result.result)\n",
    "\n",
    "# If the initial notes are not good enough, terminate the process\n",
    "if step1_result.result == \"TERMINATE PROCESS\":\n",
    "    print(\"Process terminated\")\n",
    "else:\n",
    "    # Replace abbreviations and acronyms from the input text\n",
    "    step2 = asyncio.create_task(kernel.run_async(my_functions[\"AbbreviationExpansion\"], input_str=step1_result.result))\n",
    "    step2_result = await step2\n",
    "    print(\"Abbreviations expansion result:\")\n",
    "    print(step2_result.result)\n",
    "\n",
    "    # Create the final session report, after the previous steps\n",
    "    step3 = asyncio.create_task(kernel.run_async(my_functions[\"Summarize\"], input_str=step2_result.result))\n",
    "    step3_result = await step3\n",
    "    print(\"Report result:\")\n",
    "    print(step3_result.result)\n",
    "\n",
    "    # Translate to Spanish\n",
    "    context = ContextVariables()\n",
    "    context[\"language\"] = \"spanish\"\n",
    "    context[\"input\"] = step3_result.result\n",
    "    translate = asyncio.create_task(kernel.run_async(my_functions[\"TranslateNotes\"], input_vars=context))\n",
    "    translate_result = await translate\n",
    "    print(\"Translate result:\")\n",
    "    print(translate_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "Repeat the previous step for the full document and save the document as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result = []\n",
    "\n",
    "for session in sessions:\n",
    "    input_str = session[\"content\"]\n",
    "\n",
    "    print(f\"Processing session: {session['title']}\")\n",
    "\n",
    "    # Replace abbreviations and acronyms from the input text\n",
    "    step1 = asyncio.create_task(kernel.run_async(my_functions[\"NoteReview\"], input_str=input_str))\n",
    "    step1_result = await step1\n",
    "\n",
    "    if step1_result.result == \"TERMINATE PROCESS\":\n",
    "        print(\"Process terminated\")\n",
    "        output_result.append({\"title\": session[\"title\"], \"content\": \"No notes available\"})\n",
    "    else:\n",
    "        # Review notes from the previous step, and summarize the notes\n",
    "        step2 = asyncio.create_task(kernel.run_async(my_functions[\"AbbreviationExpansion\"], input_str=step1_result.result))\n",
    "        step2_result = await step2\n",
    "\n",
    "        # Create the final session report, after the previous steps\n",
    "        step3 = asyncio.create_task(kernel.run_async(my_functions[\"Summarize\"], input_str=step2_result.result))\n",
    "        step3_result = await step3\n",
    "\n",
    "        # Translate to Spanish\n",
    "        context = ContextVariables()\n",
    "        context[\"language\"] = \"spanish\"\n",
    "        context[\"input\"] = step3_result.result\n",
    "        translate = asyncio.create_task(kernel.run_async(my_functions[\"TranslateNotes\"], input_vars=context))\n",
    "        translate_result = await translate\n",
    "\n",
    "        output_result.append({\"title\": session[\"title\"], \"content\": translate_result.result})\n",
    "\n",
    "    # Save the output to a Word document\n",
    "    output_document = Document()\n",
    "\n",
    "for session in output_result:\n",
    "    output_document.add_heading(session[\"title\"], level=1)\n",
    "    output_document.add_paragraph(session[\"content\"])\n",
    "\n",
    "output_document.save(\"output.docx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
